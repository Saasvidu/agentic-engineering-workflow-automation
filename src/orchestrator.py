"""
orchestrator.py

Agentic AI Orchestrator for Structural Engineering FEA Simulations.
Refactored to use OpenAI GPT-4o-mini.
"""

import os
import requests
from typing import TypedDict, Annotated, Optional, Sequence
from dotenv import load_dotenv

# LangChain and LangGraph imports
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
# CHANGED: Import OpenAI chat model
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages

# Local imports (Assumed to exist based on previous context)
from mcp_schema import AbaqusInput

# Load environment variables
load_dotenv()

# Configuration
# CHANGED: Loading OpenAI API Key
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
MCP_SERVER_URL = os.getenv("MCP_SERVER_URL", "http://localhost:8000")

if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY not found in environment variables.")


# ============================================================================
# STATE DEFINITION
# ============================================================================

class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]
    raw_input: str
    structured_config: Optional[AbaqusInput]
    validation_error: Optional[str]
    submission_status: Optional[str]


# ============================================================================
# LLM INITIALIZATION
# ============================================================================

# CHANGED: Initialize OpenAI GPT-4o-mini
# This model is optimized for speed and structured data extraction
llm = ChatOpenAI(
    model="gpt-4o-mini",
    api_key=OPENAI_API_KEY,
    temperature=0.0  # Deterministic for parsing
)

# Bind the LLM to output structured AbaqusInput objects
# OpenAI supports this natively and reliably
structured_llm = llm.with_structured_output(AbaqusInput)


# ============================================================================
# GRAPH NODE FUNCTIONS
# ============================================================================

def parse_request(state: AgentState) -> AgentState:
    """
    Node 1: Parse Request
    Uses OpenAI to convert natural language input into a structured
    AbaqusInput configuration.
    """
    print("ğŸ” [Node: parse_request] Extracting structured data from user input...")
    
    system_prompt = """You are an expert structural engineering assistant specializing in Finite Element Analysis (FEA).
Your task is to extract simulation parameters from natural language descriptions and format them into a structured JSON configuration.

Extract the following information:
1. MODEL_NAME: A descriptive name for the simulation
2. TEST_TYPE: One of [CantileverBeam, TaylorImpact, TensionTest]
3. GEOMETRY: Length, width, height in meters
4. MATERIAL: Name, Young's modulus (Pa), Poisson's ratio
5. LOADING: Applied forces in Newtons
6. DISCRETIZATION: Number of mesh elements along each axis

Use reasonable engineering defaults if specific values are not provided:
- Steel: E=200 GPa (200e9 Pa), Î½=0.3
- Aluminum: E=69 GPa (69e9 Pa), Î½=0.33
- Default mesh: 10 elements per dimension

Be precise with units and ensure all values are physically meaningful."""
    
    user_input = state["raw_input"]
    
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"Convert this simulation request into structured parameters: {user_input}")
    ]
    
    try:
        # Invoke the structured LLM
        structured_config = structured_llm.invoke(messages)
        
        print(f"âœ… Successfully parsed configuration:")
        print(f"   Model: {structured_config.MODEL_NAME}")
        print(f"   Test Type: {structured_config.TEST_TYPE}")
        print(f"   Material: {structured_config.MATERIAL.name}")
        
        state["structured_config"] = structured_config
        state["messages"].append(AIMessage(content=f"Successfully parsed parameters for {structured_config.MODEL_NAME}"))
        
    except Exception as e:
        error_msg = f"Failed to parse input: {str(e)}"
        print(f"âŒ {error_msg}")
        state["validation_error"] = error_msg
        state["messages"].append(AIMessage(content=error_msg))
    
    return state

# ... [The rest of the file (validate_physics, submit_job, graph definition) remains unchanged] ...

def validate_physics(state: AgentState) -> AgentState:
    # (Existing validation logic...)
    print("ğŸ”¬ [Node: validate_physics] Performing engineering validation...")
    structured_config = state.get("structured_config")
    
    if not structured_config:
        state["validation_error"] = "No structured configuration to validate"
        return state
        
    # [Insert your existing physics validation logic here]
    # For brevity, I am returning the state as-is, but you should 
    # keep your original aspect ratio and modulus checks.
    
    state["validation_error"] = None # Assume pass for this snippet
    return state

def submit_job(state: AgentState) -> AgentState:
    """
    Node 3: Submit Job
    
    Sends the validated AbaqusInput configuration to the MCP Server via POST request.
    The server will initialize a new FEA job and return a job context.
    
    Transition: Always proceeds to END (workflow complete)
    """
    print("ğŸš€ [Node: submit_job] Submitting job to MCP Server...")
    
    structured_config = state["structured_config"]
    
    # Prepare the API request
    endpoint = f"{MCP_SERVER_URL}/mcp/init"
    params = {"job_name": structured_config.MODEL_NAME}
    payload = structured_config.model_dump()
    
    try:
        # Make POST request to MCP Server with job_name as query param and config as JSON body
        response = requests.post(endpoint, params=params, json=payload, timeout=10)
        response.raise_for_status()
        
        # Parse response
        job_context = response.json()
        job_id = job_context.get("job_id", "Unknown")
        
        success_msg = (
            f"âœ… Job submitted successfully!\n"
            f"   Job ID: {job_id}\n"
            f"   Job Name: {structured_config.MODEL_NAME}\n"
            f"   Status: {job_context.get('current_status', 'INITIALIZED')}"
        )
        print(success_msg)
        
        state["submission_status"] = f"SUCCESS: Job ID {job_id}"
        state["messages"].append(AIMessage(content=success_msg))
        
    except requests.exceptions.RequestException as e:
        error_msg = f"Failed to submit job to MCP Server: {str(e)}"
        print(f"âŒ {error_msg}")
        state["submission_status"] = f"FAILED: {str(e)}"
        state["messages"].append(AIMessage(content=error_msg))
    
    return state

def should_continue_to_submit(state: AgentState) -> str:
    if state.get("validation_error"):
        return "END"
    return "submit_job"

def create_orchestrator_graph() -> StateGraph:
    workflow = StateGraph(AgentState)
    workflow.add_node("parse_request", parse_request)
    workflow.add_node("validate_physics", validate_physics)
    workflow.add_node("submit_job", submit_job)
    
    workflow.set_entry_point("parse_request")
    workflow.add_edge("parse_request", "validate_physics")
    workflow.add_conditional_edges(
        "validate_physics",
        should_continue_to_submit,
        {"submit_job": "submit_job", "END": END}
    )
    workflow.add_edge("submit_job", END)
    return workflow.compile()

def run_orchestrator(user_input: str) -> AgentState:
    print("=" * 80)
    print("ğŸ¤– AGENTIC FEA ORCHESTRATOR (OPENAI BACKEND)")
    print("=" * 80)
    print(f"ğŸ“ User Input: {user_input}\n")
    
    initial_state: AgentState = {
        "messages": [HumanMessage(content=user_input)],
        "raw_input": user_input,
        "structured_config": None,
        "validation_error": None,
        "submission_status": None
    }
    
    app = create_orchestrator_graph()
    final_state = app.invoke(initial_state)
    return final_state

if __name__ == "__main__":
    example_input = (
        "Create a cantilever beam simulation called 'Steel_Beam_Test_001'. "
        "Use a steel beam that is 2 meters long, 0.1 meters wide, and 0.05 meters tall. "
        "Apply a downward force of 5000 Newtons at the free end."
    )
    run_orchestrator(example_input)